{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "716be055",
   "metadata": {},
   "source": [
    "## BERTopic with optimal setting\n",
    "Source: https://maartengr.github.io/BERTopic/index.html#installation\n",
    "\n",
    "------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c62d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820efecc",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"orban_speeches_en_thesis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the empty cells and convert column to list\n",
    "\n",
    "docs = data['speech'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the empty cells and convert column to list\n",
    "\n",
    "docs_tokenized = data['tokenized_speech'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a9185",
   "metadata": {},
   "source": [
    "### Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove default stopwords\n",
    "\n",
    "def preprocess_data(documents, stop_words):\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    texts = [[word for word in doc.split() if word not in stop_words] for doc in documents]\n",
    " \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20685e8",
   "metadata": {},
   "source": [
    "### Corpus-specific stopwords\n",
    "based on the topic representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_spec = [\"also\",\n",
    "                  \"well\",\n",
    "                  \"like\",\n",
    "                  \"would\",\n",
    "                  \"must\",\n",
    "                  \"weve\", \n",
    "                  \"theres\", \n",
    "                  \"theyre\", \n",
    "                  \"dont\", \n",
    "                  \"isnt\", \n",
    "                  \"sz00f6vegtestchar\", #meta\n",
    "                  \"sz00f6vegtest\", #meta\n",
    "                  #\"normalchar\", #meta\n",
    "                  \"span\", #meta\n",
    "                  \"pcs\", # interviewer Péter Csermely's monogram\n",
    "                  \"gik\", # interviewer Gábor István Kiss's monogram\n",
    "                  \"vo\"] # prime minister Viktor Orbán's monogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56908d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom stopwords\n",
    "\n",
    "sopwords_custom = stopwords_spec + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af6353",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73c044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pre-calculate embeddings --> feed them to BERTopic to skip calculating embeddings each time\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea4136b",
   "metadata": {},
   "source": [
    "### Removing stopwords\n",
    "It is important to include all the words when embedding! The methods below will help in the model to remove them later when creating the topic representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e80d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. option: CountVectorizer -- removes specified words\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=sopwords_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. option: ClassTfidfTransformer -- redues the occurrence of frequent words in the representations\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. option: KeyBERT-Inspired model -- in theory reduces the occurrance of frequent words and improves the representations\n",
    "\n",
    "#representation_model = KeyBERTInspired()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be5268",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db76073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning UMAP -\n",
    "\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15, # number of neighboring sample points used when making the manifold approximation (higher --> larger clusters)\n",
    "    n_components=5, # dimensionality of the embeddings after reducing them (too high --> hard time clustering, too low --> too little information)\n",
    "    metric='cosine', \n",
    "    random_state=42 # for the sake of reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd656c66",
   "metadata": {},
   "source": [
    "### Clastering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f76b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning HDBSCAN -- to indirectly reduce topic numbers\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a63f0",
   "metadata": {},
   "source": [
    "### Topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2da588",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(\n",
    "    # pipeline models\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    #embedding_model=embedding_model, #uncomment if representation_model is used\n",
    "    \n",
    "    # remove stop words\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    #representation_model=representation_model,\n",
    "    \n",
    "    # hyperparameters\n",
    "    top_n_words = 10, # number of returned topic words\n",
    "    n_gram_range = (1, 2), # possibility to return two-word phrases\n",
    "    min_topic_size = 5, # minimum number of returned topics (default = 10)\n",
    "    nr_topics = 'auto',\n",
    "    low_memory = False, # set to True if yor computer needs it\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs_tokenized, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4449b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return generated topics\n",
    "\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the topic words, outlier topic excluded (list of list of str)\n",
    "\n",
    "topic_list = topic_model.get_topic_info()[\"Representation\"].to_list()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a608b",
   "metadata": {},
   "source": [
    "### Saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e737ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics=topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ed929",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_df = pd.DataFrame()\n",
    "\n",
    "# Iterates throught the dictionary and creates a DataFrame\n",
    "for key, values in all_topics.items():\n",
    "    words = [pair[0] for pair in values]\n",
    "    probs = [pair[1] for pair in values]\n",
    "    all_topics_df[f\"{key}_word\"] = words\n",
    "    all_topics_df[f\"{key}_prob\"] = probs\n",
    "\n",
    "print(all_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df\n",
    "all_topics_df.to_excel(\"Topic_outputs/BERTopic_opt_best_v2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1bb616",
   "metadata": {},
   "source": [
    "### Coherence score\n",
    "**<span style=\"color: crimson\"> Important! For this part, top_n_words must set to 25 in the model!</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = preprocess_data(docs_tokenized, sopwords_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary (the dictionary is a mapping between words and their integer IDs)\n",
    "id2word = corpora.Dictionary(processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef016d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluate the model using the coherence score\n",
    "coherence_model = CoherenceModel(topics=topic_list, \n",
    "                                 texts=processed_texts, \n",
    "                                 dictionary=id2word, \n",
    "                                 coherence=\"c_npmi\")\n",
    "\n",
    "coherence = coherence_model.get_coherence()\n",
    "print(\"Coherence Score: \", coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748693c8",
   "metadata": {},
   "source": [
    "### Topic diversity\n",
    "**<span style=\"color: crimson\"> Important! For this part, top_n_words must set to 25 in the model!</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list_all = [word for topic in topic_list for word in topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic diversity = ratio of unique words in the top 25 words of topics\n",
    "# by converting a list to set, it removes the duplicates\n",
    "\n",
    "topic_diversity = len(set(topic_list_all))/len(topic_list_all)\n",
    "print(topic_diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0f1c6",
   "metadata": {},
   "source": [
    "### Set topic labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f557a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.set_topic_labels(\n",
    "    {0: \"Általános\", \n",
    "     1: \"Covid\", \n",
    "     2: \"Törökország & Egyiptom\",\n",
    "     3: \"Egyház\",\n",
    "     4: \"Igazságszolgáltatás\",\n",
    "     5: \"Választás\",\n",
    "     6: \"Kína\",\n",
    "     7: \"Európa\",\n",
    "     8: \"Ukrajna\",\n",
    "     9: \"Olimpia\",\n",
    "     10: \"Orosz-ukrán háború\",\n",
    "     11: \"Orosz együttműködés\",\n",
    "     12: \"Sport & egyetem\",\n",
    "     13: \"Általános lakossági\",\n",
    "     14: \"Nyugdíj\",\n",
    "     15: \"Településfejlesztés\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700643a",
   "metadata": {},
   "source": [
    "### Topic visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceaa9b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_topics(width=600, height=700, title=\"\") #custom_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap(custom_labels=True, width=700, height = 600, title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c06d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(\n",
    "    docs_tokenized, \n",
    "    embeddings=embeddings, \n",
    "    #hide_annotations=True, \n",
    "    width=900, \n",
    "    height=800, \n",
    "    title=\"\",\n",
    "    custom_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c571a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy(custom_labels=True, width= 800, title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055a89c",
   "metadata": {},
   "source": [
    "### Saving model (serialization)\n",
    "https://maartengr.github.io/BERTopic/getting_started/serialization/serialization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"Modellek/bertopic_opt\", serialization=\"pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
