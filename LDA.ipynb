{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c1d69e",
   "metadata": {},
   "source": [
    "# LDA model\n",
    "\n",
    "The codes are partially based on: https://bennett-holiday.medium.com/a-step-by-step-guide-to-writing-an-lda-program-in-python-690aa99119ea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478de2c0",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1964af-4101-4a85-8554-97539cb1b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel \n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import nltk\n",
    "#nltk.download(\"stopwords\") #uncomment if needed\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983d958",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b7786-47ab-4934-a130-ac73d0ef0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"orban_speeches_en_thesis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6cf7f-2e13-4305-993c-2ec8931bc86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data['tokenized_speech'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812f3a1",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8946a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the speeches into one string\n",
    "\n",
    "speeches_longstring = ' '.join(map(str, list(documents.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76932567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove default stopwords to find other frequent words beyond them\n",
    "\n",
    "stop_words_default = stopwords.words(\"english\")\n",
    "tokenize_words = speeches_longstring.split()\n",
    "filtered_speeches_lst = [w for w in tokenize_words if not w in stop_words_default]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make a list of the most common n words\n",
    "## if n parameter isn't specified by the user, it returns all of the words from the list\n",
    "\n",
    "def freq_topn(str_list, n = None):\n",
    "    frequency = Counter(str_list).most_common(n)\n",
    "    freq_topn_list = []\n",
    "    \n",
    "    for tupl in frequency:\n",
    "        freq_topn_list.append(tupl[0])\n",
    "        \n",
    "    return freq_topn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find tokens ending in \".hu\" and make a list of them\n",
    "    \n",
    "def get_hu(str_list):\n",
    "    hu_set = {x for x in str_list if re.search(r'\\.hu$', x)}\n",
    "    hu_list = list(hu_set)\n",
    "    return hu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove specified stopwords\n",
    "\n",
    "def preprocess_data(documents, stop_words):\n",
    " \n",
    "    # Tokenize and remove stopwords\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in documents]\n",
    " \n",
    "    return texts\n",
    "\n",
    "# instead of \"simple_preprocess(str(doc))\", \"doc.split()\" and \"re.split(\" |'\", doc)\" were tried also\n",
    "# \"simple_preprocess(str(doc))\" performed best in terms of the coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d575c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom stopwords\n",
    "\n",
    "stop_words_custom = stopwords.words(\"english\") + freq_topn(filtered_speeches_lst, 95) + get_hu(filtered_speeches_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a8692-4df1-4aa5-b49f-e672c20cb592",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = preprocess_data(documents, stop_words_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9758975",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af682c0-f269-4ce2-994c-a5c205fe72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Corpus (the corpus is a list of documents represented as a bag-of-words (BoW))\n",
    "texts = processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914fbeff-e5d5-4605-86c5-66055aafb969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary (the dictionary is a mapping between words and their integer IDs)\n",
    "id2word = corpora.Dictionary(processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2d4ec-46af-4c25-9f74-b372be48590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4415e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of topics\n",
    "num_topics = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f73da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = LdaModel(corpus=corpus, \n",
    "                     id2word=id2word, \n",
    "                     num_topics=num_topics, \n",
    "                     random_state=42) \n",
    "                     #passes=10, # Number of passes through the corpus during training. - mi a default?\n",
    "                     #alpha=\"auto\", # default prior selecting strategies - ’auto’: Learns an asymmetric prior from the corpus\n",
    "                     #per_word_topics=True) # If True, the model also computes a list of topics, sorted in descending order of most likely topics for each word, along with their phi values multiplied by the feature length (i.e. word count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd306b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the topics\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d033e",
   "metadata": {},
   "source": [
    "### Saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cd57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics=lda_model.show_topics(num_topics=20, num_words=25, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_df = pd.DataFrame()\n",
    "words = []\n",
    "probs = []\n",
    "\n",
    "# Iteráljunk a dictionary-n és hozzuk létre a DataFrame-et\n",
    "for topic in all_topics:\n",
    "    words = [token[0] for token in topic[1]]\n",
    "    probs = [token[1] for token in topic[1]]\n",
    "    all_topics_df[f\"{topic[0]}_word\"] = words\n",
    "    all_topics_df[f\"{topic[0]}_prob\"] = probs\n",
    "\n",
    "#print(all_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df\n",
    "all_topics_df.to_excel(\"Topic_outputs/Final/LDA_25words.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b9bbb",
   "metadata": {},
   "source": [
    "### Coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For coherence score, the top 10 topic words are needed\n",
    "x=lda_model.show_topics(num_topics=20, num_words=10, formatted=False)\n",
    "topic_list_10 = [[word[0] for word in topic[1]] for topic in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the coherence score\n",
    "coherence_model = CoherenceModel(topics=topic_list_10,\n",
    "                                 texts=processed_texts,\n",
    "                                 dictionary=id2word,\n",
    "                                 coherence=\"c_npmi\")\n",
    "\n",
    "coherence = coherence_model.get_coherence()\n",
    "print(\"Coherence Score: \", coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a00d0d",
   "metadata": {},
   "source": [
    "### Topic diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39781529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For topic diversity, the top 25 topicwords are needed\n",
    "x=lda_model.show_topics(num_topics=20, num_words=25, formatted=False)\n",
    "topic_list_25 = [[word[0] for word in topic[1]] for topic in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81776731",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list_all = [word for topic in topic_list_25 for word in topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic diversity = ratio of unique words in the top 25 words of topics\n",
    "# by converting a list to set, it removes the duplicates\n",
    "\n",
    "topic_diversity = len(set(topic_list_all))/len(topic_list_all)\n",
    "print(topic_diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1bbe6",
   "metadata": {},
   "source": [
    "### Custom labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of custom topiclabels\n",
    "\n",
    "labels = [\"Támogatás & EU\",\n",
    "         \"Kereszténység & siker\",\n",
    "         \"Migráció & krízis\",\n",
    "         \"Támogatás & választás\",\n",
    "         \"Szerbia & nehézség\",\n",
    "         \"Brüsszel & külföld\",\n",
    "         \"Hosszútávú & növekedés\",\n",
    "         \"Energia & fejlődés\",\n",
    "         \"Nyugat & problémák\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38589561",
   "metadata": {},
   "source": [
    "### Topic visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9332010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: https://pyldavis.readthedocs.io/en/latest/modules/API.html\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, \n",
    "                              corpus, \n",
    "                              dictionary=lda_model.id2word,\n",
    "                              R = 10,\n",
    "                              plot_opts={'xlab': 'D1', 'ylab': 'D2'},\n",
    "                              sort_topics=False)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://radimrehurek.com/gensim/auto_examples/howtos/run_compare_lda.html\n",
    "\n",
    "def plot_difference(mdiff, labels=None, title=\"\", annotation=None): # módosítás: labels paraméter\n",
    "    \"\"\"Plot the difference between models.\n",
    "\n",
    "    Uses plotly as the backend.\"\"\"\n",
    "    import plotly.graph_objs as go\n",
    "    import plotly.offline as py\n",
    "\n",
    "    annotation_html = None\n",
    "    if annotation is not None:\n",
    "        annotation_html = [\n",
    "            [\n",
    "                \"+++ {}<br>--- {}\".format(\", \".join(int_tokens), \", \".join(diff_tokens))\n",
    "                for (int_tokens, diff_tokens) in row\n",
    "            ]\n",
    "            for row in annotation\n",
    "        ]\n",
    "\n",
    "    data = go.Heatmap(z=mdiff, colorscale= \"viridis\", text=annotation_html, x=labels, y=labels) # modification: color scale and x=labels, y=labels\n",
    "    layout = go.Layout(width=500, height=500, title=\"\")  # modification: axis labels are removed\n",
    "    py.iplot(dict(data=[data], layout=layout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962667a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the topics based on Kullback-Leibler Distance\n",
    "\n",
    "mdiff, annotation = lda_model.diff(lda_model, distance='kullback_leibler')\n",
    "plot_difference(mdiff, annotation=annotation, labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863167e4",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074616ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This algorithm was used to optimalize the model\n",
    "\n",
    "for i in range(1,21, 1):\n",
    "    \n",
    "    num_topics = i\n",
    "    \n",
    "    lda_model = LdaModel(corpus=corpus, \n",
    "                         id2word=id2word, \n",
    "                         num_topics=num_topics, \n",
    "                         random_state=42) \n",
    "    \n",
    "    x=lda_model.show_topics(num_topics=20, num_words=10, formatted=False)\n",
    "    topic_list_10 = [[word[0] for word in topic[1]] for topic in x]\n",
    "\n",
    "    coherence_model_lda = CoherenceModel(topics=topic_list_10,\n",
    "                                         #model=lda_model, \n",
    "                                         texts=processed_texts, \n",
    "                                         dictionary=id2word, \n",
    "                                         coherence=\"c_npmi\")\n",
    "    \n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print(f\"Number of topics: {i} -- Coherence Score: {coherence_lda}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
